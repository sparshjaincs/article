{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'desired_characs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-879664587ab2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;34m'titles'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdesired_characs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtitles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'titles'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'desired_characs' is not defined"
     ]
    }
   ],
   "source": [
    "jobs = \"python\"\n",
    "location = \"Jaipur\"\n",
    "url = f\"https://www.indeed.co.in/jobs?q={jobs}&l={location}\"\n",
    "data = requests.get(url)\n",
    "data = data.content\n",
    "soup = bs(data,\"html.parser\")\n",
    "job_soup = soup.find(id=\"resultsCol\")\n",
    "job_elems = job_soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "\n",
    "cols = []\n",
    "extracted_info = []\n",
    "\n",
    "\n",
    "if 'titles' in desired_characs:\n",
    "    titles = []\n",
    "    cols.append('titles')\n",
    "    for job_elem in job_elems:\n",
    "        titles.append(extract_job_title_indeed(job_elem))\n",
    "    extracted_info.append(titles)                    \n",
    "\n",
    "if 'companies' in desired_characs:\n",
    "    companies = []\n",
    "    cols.append('companies')\n",
    "    for job_elem in job_elems:\n",
    "        companies.append(extract_company_indeed(job_elem))\n",
    "    extracted_info.append(companies)\n",
    "\n",
    "if 'links' in desired_characs:\n",
    "    links = []\n",
    "    cols.append('links')\n",
    "    for job_elem in job_elems:\n",
    "        links.append(extract_link_indeed(job_elem))\n",
    "    extracted_info.append(links)\n",
    "\n",
    "if 'date_listed' in desired_characs:\n",
    "    dates = []\n",
    "    cols.append('date_listed')\n",
    "    for job_elem in job_elems:\n",
    "        dates.append(extract_date_indeed(job_elem))\n",
    "    extracted_info.append(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_indeed(job_elem):\n",
    "    title_elem = job_elem.find('h2', class_='title')\n",
    "    title = title_elem.text.strip()\n",
    "    return title\n",
    "\n",
    "def extract_company_indeed(job_elem):\n",
    "    company_elem = job_elem.find('span', class_='company')\n",
    "    company = company_elem.text.strip()\n",
    "    return company\n",
    "\n",
    "def extract_link_indeed(job_elem):\n",
    "    link = job_elem.find('a')['href']\n",
    "    link = 'www.Indeed.co.uk/' + link\n",
    "    return link\n",
    "\n",
    "def extract_date_indeed(job_elem):\n",
    "    date_elem = job_elem.find('span', class_='date')\n",
    "    date = date_elem.text.strip()\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indeed_jobs_div(jobs,location):\n",
    "    url = f\"https://www.indeed.co.in/jobs?q={jobs}&l={location}\"\n",
    "    data = requests.get(url)\n",
    "    data = data.content\n",
    "    soup = bs(data,\"html.parser\")\n",
    "    job_soup = soup.find(id=\"resultsCol\")\n",
    "    return job_soup\n",
    "\n",
    "    \n",
    "\n",
    "def find_jobs_from(website, job_title, location, desired_characs, filename=\"results.xls\"):    \n",
    "    \"\"\"\n",
    "    This function extracts all the desired characteristics of all new job postings\n",
    "    of the title and location specified and returns them in single file.\n",
    "    The arguments it takes are:\n",
    "        - Website: to specify which website to search (options: 'Indeed' or 'CWjobs')\n",
    "        - Job_title\n",
    "        - Location\n",
    "        - Desired_characs: this is a list of the job characteristics of interest,\n",
    "            from titles, companies, links and date_listed.\n",
    "        - Filename: to specify the filename and format of the output.\n",
    "            Default is .xls file called 'results.xls'\n",
    "    \"\"\"\n",
    "    \n",
    "    if website == 'Indeed':\n",
    "        job_soup = load_indeed_jobs_div(job_title, location)\n",
    "        jobs_list, num_listings = extract_job_information_indeed(job_soup, desired_characs)\n",
    "    \n",
    "    if website == 'CWjobs':\n",
    "        # TO DO LATER\n",
    "        pass\n",
    "    \n",
    "    #save_jobs_to_excel(jobs_list, filename)\n",
    " \n",
    "def extract_job_information_indeed(job_soup, desired_characs):\n",
    "    job_elems = job_soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "     \n",
    "    cols = []\n",
    "    extracted_info = []\n",
    "    \n",
    "    \n",
    "    if 'titles' in desired_characs:\n",
    "        titles = []\n",
    "        cols.append('titles')\n",
    "        for job_elem in job_elems:\n",
    "            titles.append(extract_job_title_indeed(job_elem))\n",
    "        extracted_info.append(titles)                    \n",
    "    \n",
    "    if 'companies' in desired_characs:\n",
    "        companies = []\n",
    "        cols.append('companies')\n",
    "        for job_elem in job_elems:\n",
    "            companies.append(extract_company_indeed(job_elem))\n",
    "        extracted_info.append(companies)\n",
    "    \n",
    "    if 'links' in desired_characs:\n",
    "        links = []\n",
    "        cols.append('links')\n",
    "        for job_elem in job_elems:\n",
    "            links.append(extract_link_indeed(job_elem))\n",
    "        extracted_info.append(links)\n",
    "    \n",
    "    if 'date_listed' in desired_characs:\n",
    "        dates = []\n",
    "        cols.append('date_listed')\n",
    "        for job_elem in job_elems:\n",
    "            dates.append(extract_date_indeed(job_elem))\n",
    "        extracted_info.append(dates)\n",
    "    \n",
    "    jobs_list = {}\n",
    "    \n",
    "    for j in range(len(cols)):\n",
    "        jobs_list[cols[j]] = extracted_info[j]\n",
    "    \n",
    "    num_listings = len(extracted_info[0])\n",
    "    \n",
    "    return jobs_list, num_listings\n",
    "    print('{} new job postings retrieved. Stored in {}.'.format(num_listings, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired = ['titles','companies','links','date_listed']\n",
    "find_jobs_from('Indeed','data science','london',desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scrapper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_indeed(self,jobs,location):\n",
    "        url = f\"https://www.indeed.co.in/jobs?q={jobs}&l={location}\"\n",
    "        data = requests.get(url)\n",
    "        data = data.content\n",
    "        soup = bs(data,\"html.parser\")\n",
    "        job_soup = soup.find(id=\"resultsCol\")\n",
    "        return job_soup\n",
    "    def indeed_title(self,element):\n",
    "        try:\n",
    "            title_elem = element.find('h2', class_='title')\n",
    "            title = title_elem.text.strip()\n",
    "        except:\n",
    "            title = \"\"\n",
    "        return title\n",
    "    def indeed_summary(self,element):\n",
    "        try:\n",
    "            summary = element.find('div',class_ = 'summary')\n",
    "            summary = summary.text\n",
    "        except:\n",
    "            summary = \"\"\n",
    "        return summary\n",
    "    def extract_company_indeed(self,job_elem):\n",
    "        db = {}\n",
    "        try:\n",
    "            company_elem = job_elem.find('div', class_='sjcl')\n",
    "            company_data = company_elem.find('span',class_ = 'company')\n",
    "            company = company_data.text.strip()\n",
    "        except:\n",
    "            company = \"\"\n",
    "            \n",
    "        try:\n",
    "            location_data = company_elem.find('span',class_ = 'location')\n",
    "            location = location_data.text.strip()\n",
    "        except:\n",
    "            location=\"\"\n",
    "        #remote_data = company_elem.find('span',class_ = 'remote')\n",
    "        #remote = remote_data.text.strip()\n",
    "        #req_data = company_elem.find('div',class_='summary')\n",
    "        #req = req_data.text.strip()\n",
    "        \n",
    "        \n",
    "        db['company'] = company\n",
    "        db['location'] = location\n",
    "        #db['requirement'] = req_data\n",
    "        #db['method'] = remote\n",
    "        return db\n",
    "\n",
    "    def extract_link_indeed(self,job_elem):\n",
    "        link = job_elem.find('a')['href']\n",
    "        link = 'https://www.Indeed.co.uk/' + link\n",
    "        return link\n",
    "    def extract_requirement(self,element):\n",
    "        #req_elem = element.find('div', class_='jobCardReqContainer')\n",
    "        try:\n",
    "            data = element.find('div',class_ = 'jobCardReqList')\n",
    "            sol = \"\"\n",
    "            for i in data.find_all('div',class_='jobCardReqItem'):\n",
    "                sol += i.text.strip() + '\\n'\n",
    "            \n",
    "        except:\n",
    "            sol = \"\"\n",
    "        #req = req_elem.text.strip()\n",
    "        return sol\n",
    "    def extract_date_indeed(self,job_elem):\n",
    "        try:\n",
    "            date_elem = job_elem.find('span', class_='date')\n",
    "            date = date_elem.text.strip()\n",
    "        except:\n",
    "            date=\"\"\n",
    "        return date\n",
    "    \n",
    "        \n",
    "    def get_indeed_job_data(self,instance):\n",
    "        db = list()\n",
    "        data = instance.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "        for x in data:\n",
    "            sol = dict()\n",
    "        \n",
    "            title = self.indeed_title(x)\n",
    "            company = self.extract_company_indeed(x)\n",
    "            link = self.extract_link_indeed(x)\n",
    "            date = self.extract_date_indeed(x)\n",
    "            summary = self.indeed_summary(x)\n",
    "            req = self.extract_requirement(x)\n",
    "            \n",
    "            sol['title'] = title\n",
    "            sol['company'] = company\n",
    "            sol['link'] = link\n",
    "            sol['date'] = date\n",
    "            sol['summary'] = summary\n",
    "            sol['requirement'] = req\n",
    "            db.append(sol)\n",
    "        return db\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def find_jobs(self,website,jobs,location):\n",
    "        if website  == 'Indeed':\n",
    "            soup = self.load_indeed(jobs,location)\n",
    "            information = self.get_indeed_job_data(soup)\n",
    "            return information\n",
    "            \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Backend Developer for a Product Based Edutech Company',\n",
       "  'company': {'company': 'Shaw Academy', 'location': ''},\n",
       "  'link': 'www.Indeed.co.uk//pagead/clk?mo=r&ad=-6NYlbfkN0CNc4hWJXeDZ3ZXnFcr2J1Wj0e9JtA8O3MaJxzvzfN414ttxYRoeU1mdn94ev3SCerd4lfvGv9Vr6sZMwFcSDwZ4P3Uyz0koeBg2Ht2j4HHiGdVoUKO3zkbSlA30bp90twhK9HNmdFK-mHmHR9tUxz2UjJNwmUeDSa86azssrNVGEo8XO33mzMrOeUienqfu1w6xLGHNWLS0YJbf8Xty66oS0yvK4Aoi3mKiIO5MScUku7hg9Dn95nULWhUgOCKQfJnLYTmg-OCGHyaG83ihAhQ05S93Uoo2KOwvewlIGhwi89bf0gtRaUQKTQgZh4NMNS2Btp7wYfdA3ty8-yu4sbHRA-hWyv8yiaSKJMtn372on32NhvLor2FqLOQ0wngOfPlQR9C76W1cQW0zS_mtIoG3yGHemM0pBYhEmRHg1gntUSDlNwut8AxElOawrHeJmavaHjUDnjPNm6uQ7iHDnfQZV2_seT-N5UTQTaCXTq2JzeHWsPIC-1P&p=0&fvj=1&vjs=3',\n",
       "  'date': '10 days ago',\n",
       "  'summary': '\\n\\nBackend developer with hands-on programming experience in Node Js / Python / Golang.\\nExpertise in developing REST APIs with any backend framework using above…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Python Developer\\nnew',\n",
       "  'company': {'company': 'Client of Neo Credence Consultancy', 'location': ''},\n",
       "  'link': 'www.Indeed.co.uk//pagead/clk?mo=r&ad=-6NYlbfkN0DrAzIi9IokD1wYH2CV73iQC1qeslHcMAIhImCgZg4CF4ZfxO7iCXvi329spECIsZR79DneBHMxzx3muEJqg3wvMGAotv4azduzPf1Z4I6D3Mm6VJ9od_DcE14VoP5EqmTulOIPRV7ZLP9uhZw1Jv3m_gMD2ScIegtLNzO4NbavJphlgOnTOShN4rs3cVdnrRyA36J_nGYcdCs6JP6UayUFtxVvPxDIwzGZOAWxdbpcbw0_DJ4yS8W5c_yQZzrRAb20QhQXihNeCFhOsoepNqQpWju5Ib3zJ64C5boosAGZs0eAWVqep991EUcMxWmZKhlVC4MyUx5kdLBPODwm3tMkRFgEuMQ8torX88qbYUV48piyOo7JkH_HFH7s2dnrZrvbyVs4IiHfkLj99hPza4D2BrdnWQY4QD50c6sLMOuVHVqlUO6zRxkvJ9Vms15qfHw=&p=1&fvj=1&vjs=3',\n",
       "  'date': '3 days ago',\n",
       "  'summary': '\\n\\nSkills: Python, Javascript, Django, ReactJs, AngularJs, SQL, etc.\\n4.5 + years of experience.\\n15 to 20 days notice period.\\nTotal work: 4 years (Preferred).\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Senior Software Engineer (Python)',\n",
       "  'company': {'company': 'SearchBlox Software, Inc.', 'location': ''},\n",
       "  'link': 'www.Indeed.co.uk//pagead/clk?mo=r&ad=-6NYlbfkN0BbHo_KG3m_RLQU1j8rpX_Vwrk2vKyvalo5bB1NEpNc2WuefVGyIKYeBw6_2NnHngAFB1K9e3-7qF4wSzw0kRjohVDnuKNaa9gPjgSgvWq50vS9Xrp5TPMI2Mk7zWEwllaiH3I54W39y1-ym2fueF8ajj_y80snGDhhikWh24A89IWzXaocIAqcv6YA6jadCjobWE8X8AsNnjIwl_AkRr4CoOXjxkjway-3yaKAcSWFWxE6uP3BmEbnutkaTspSby6PNjiHIoHFdN-JfGkt0815Trv_gaqXRcb_n9TdiGnHUmSHVbQ9YFM1WCVVO7-QadVpimcDMNwTWZd6OQ9O4-pDCJooTKF-WubtgHxkPQwis4CFimcnCxs8sTZ9gCZhm6Ztkw9ylrJI4Shf4kbAJXUsxIBJ4_8QF3OGyYuQ1jHuLRRzgphiAkgzpyFxL6dg49_wNKVVP0M4KA==&p=2&fvj=1&vjs=3',\n",
       "  'date': '18 days ago',\n",
       "  'summary': '\\n\\nDeveloping new software and helping build out microservice architecture is a big portion of this position.\\nLooking for engineers that are passionate about their…\\n',\n",
       "  'requirement': \"Bachelor's\\n\"},\n",
       " {'title': 'Test lead Engineer\\nnew',\n",
       "  'company': {'company': 'Qapitol QA', 'location': ''},\n",
       "  'link': 'www.Indeed.co.uk//pagead/clk?mo=r&ad=-6NYlbfkN0B_jW6BFrvQjZJ6Tsr2QqLE5UbjaAEU-tJOKWHJJACDpixkHhqjAXF_PTAAVK-TyyN05TyoQwIwMqwpihifSjTpgDRC3EAkB2DBqYktG6WszoS3HfCdqRKYyqaQ8hT5CeDwm836uK_swzPVdjpdUXq3uhxClxAKJxHKJ4Wm67MLt8qeoJqojbUHGy2VKPskfqqRI5BTKbBb4jyqpsGhmt8b0WjJMW_Eft6zt9Qp4QeZ2yH9cU1MDH5drLGkuI-IKNKHiA8yArTgPtOivTsFIuTuCEPw0iqYGd4n3zv7mQQgQo_omMyzv8k-aopONFvMg4l-A2sD6ApTb8M5A3y5lSCOqn9WJE_GUOSWstM4vPc086pSmee66PhxWiCYEdOM8VTGCy39ZjQ0LWgoOYkKekahlfuUuIin6jNgIozUY-HkaWWS_prZieVQS8Fw78mi-NU=&p=3&fvj=1&vjs=3',\n",
       "  'date': '2 days ago',\n",
       "  'summary': '\\n\\nQapitol QA works with leading companies, of which some are unicorns with innovative products and award-winning technology solutions.\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'PYTHON AUTOMATION TESTING\\nnew',\n",
       "  'company': {'company': 'SpanIdea', 'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=2a0cb4d1d77d6a01&fccid=7240b32aaf9dcf59&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\n5 plus years of experience in the field of QA and along with the following requirements:\\nStrong understanding of Software quality testing and Software…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Commercial Banking - Data Analysis and Reporting -SSIS/SSRS/...\\nnew',\n",
       "  'company': {'company': 'JPMorgan Chase Bank, N.A.',\n",
       "   'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=a39171c46c00083e&fccid=aaf3b433897ea465&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\nAnalyze large amounts of data to draw and communicate business insights to Senior stakeholders.\\nCritically assess current reporting infrastructure for…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Associate\\nnew',\n",
       "  'company': {'company': 'Cognizant', 'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=a5c400161d9de544&fccid=2df6a1e69a70a1e7&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': \"\\n\\nBachelor's in Science/ Commerce/Engineering or equivalent.\\nPerform SOP activities with business impact understanding of customer environment and contribute to…\\n\",\n",
       "  'requirement': ''},\n",
       " {'title': 'Python/Django Developer\\nnew',\n",
       "  'company': {'company': 'Sachirva Technology Solutions',\n",
       "   'location': 'Jayanagar, Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//company/Sachirva-Technology-Solutions/jobs/Python-Django-Developer-6758aa61a0254ada?fccid=24663d042080e923&vjs=3',\n",
       "  'date': '6 days ago',\n",
       "  'summary': '\\n\\nSachirva Technology Solutions Pvt. Ltd. is a young multi-disciplinary Development, Design, and Marketing firm providing Web & Mobile Apps Development, Digital…\\n',\n",
       "  'requirement': 'Django: 2 years\\nPython: 2 years\\nMangoDB: 2 years\\n'},\n",
       " {'title': 'Selenium robotframework Python\\nnew',\n",
       "  'company': {'company': 'OBOlinx Tech', 'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=04014a9e8d43a7ef&fccid=19e908269ece67c7&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\nExperience in Robot Framework Selenium Gherkins Experience in working in Agile methodology Develop a library of test scripts using the Robot Selenium test…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Hive , Hadoop, Spark , Python , Unix shell scripting\\nnew',\n",
       "  'company': {'company': 'Diverse Lynx India',\n",
       "   'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=eac75a3c6470ce36&fccid=f6ce40c91e89f80b&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\n5+ Years of working experience in Bigdata ( Hive and Spark).\\n3+ Years of experience in Unix shell scripting.\\nKnowledge/ experience on Python is good to have.\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Software Engineering - Python Developer\\nnew',\n",
       "  'company': {'company': 'JPMorgan Chase Bank, N.A.',\n",
       "   'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=ee76b5e8ca803a0e&fccid=aaf3b433897ea465&vjs=3',\n",
       "  'date': '5 days ago',\n",
       "  'summary': '\\n\\nJPMorgan Chase & Co. (NYSE: JPM) is a leading global financial services firm with assets of $2.5 trillion & operations worldwide.\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Python Developer\\nnew',\n",
       "  'company': {'company': 'Pace Wisdom Solutions Pvt Ltd',\n",
       "   'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//company/PACE-Wisdom-Solutions-PVT-LTD/jobs/Python-Developer-49f7bacf74c701e3?fccid=aab219c6996f1cc4&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\nDevelop back-end components to improve responsiveness and overall performance.\\nIntegrate user-facing elements into applications.\\nTotal work: 2 years (Required).\\n',\n",
       "  'requirement': 'Work: 2 years\\nTotal work: 2 years\\n'},\n",
       " {'title': 'PYTHON DEVELOPER – DJANGO/FLASK\\nnew',\n",
       "  'company': {'company': 'SpanIdea', 'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=9d01d581c3532bbc&fccid=7240b32aaf9dcf59&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\nExpert in Python, with knowledge of at least one Python web framework such as Django, Flask, etc.\\nFamiliarity with some ORM (Object Relational Mapper) libraries…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Python Programming Language',\n",
       "  'company': {'company': 'Accenture', 'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=fc811687f7222e58&fccid=a4e4e2eaf26690c9&vjs=3',\n",
       "  'date': '9 days ago',\n",
       "  'summary': '\\n\\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive,…\\n',\n",
       "  'requirement': ''},\n",
       " {'title': 'Associate - Treasury Analytics\\nnew',\n",
       "  'company': {'company': 'JPMorgan Chase Bank, N.A.',\n",
       "   'location': 'Bengaluru, Karnataka'},\n",
       "  'link': 'www.Indeed.co.uk//rc/clk?jk=c8c7b093387b3b38&fccid=aaf3b433897ea465&vjs=3',\n",
       "  'date': '1 day ago',\n",
       "  'summary': '\\n\\nCCB - Financial Analysis, Treasury - Associate.\\nThe Associate is responsible for supporting the Treasury finance function within Consumer & Community Banking …\\n',\n",
       "  'requirement': ''}]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = Scrapper()\n",
    "data = da.find_jobs('Indeed','python','bangalore')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
